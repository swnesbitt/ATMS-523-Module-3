{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a5463c1d",
   "metadata": {},
   "source": [
    "# ATMS 523 Module 3 Homework\n",
    "Megan Walker-Radtke\n",
    "\n",
    "## Instructions\n",
    "1. Adapt the code from class that reads GHCN Daily Data from Amazon Web Services and write a function that will download the station you want (called with a GHCN station ID), and calculate the all time record high and low and the normal (mean) high and low temperature for the 1991-2020 period for the desired station and returns a pandas data frame with the columns ['record_min_temp', average_min_temp', 'average_max_temp', record_max_temp'].  Write a code that can call this function and successfully demonstrate that it works.\n",
    "\n",
    "2. Develop a plot (using matplotlib) that displays for the city of choice a plot showing the record, average, and actual high and low temperatures for that year and city.  \n",
    "     \n",
    "     You are permitted to use the \"weather\" example from the `bokeh` gallery as inspiration.  A running example for what the plot could look like is here: [Weather](https://demo.bokeh.org/weather), and the GitHub repository for the dashboard is [here](https://github.com/bokeh/bokeh/tree/branch-3.9/examples/server/app/weather). Note that you do not have to use bokeh for this assignment, you can use matplotlib!\n",
    "\n",
    "## Approach\n",
    "### Write a function to calculate the station climatology\n",
    "1. Download GHCN Daily Data from AWS S3 for a station of interest using adaptation of code presented in class\n",
    "2. NaN check:\n",
    "     - vars: tmax, tmin\n",
    "     - print: total number of NaNs\n",
    "     - plot: timeline showing dates with NaNs (purpose: ID whether stations has large data gaps)\n",
    "3. Calculate climatology:\n",
    "     - Pull out subset of data for 1991 - 2020\n",
    "     - Groupby day of the year (e.g. all Jan1 together, all Jan2 together, etc.)\n",
    "     - Calculate extremes for each day of the year \n",
    "          - all-time tmax\n",
    "          - all-time tmin\n",
    "     - Calculate means for each day of the year\n",
    "          - mean tmax\n",
    "          - mean tmin\n",
    "4. Save the station climatology to Pandas DF with rows (index) being day of the year and columns ['record_min_temp', average_min_temp', 'average_max_temp', record_max_temp']\n",
    "\n",
    "### Create a plot that compares daily temperatures in a given year to the 1991-2020 climatology\n",
    "Plot elements:\n",
    "1. Climatology\n",
    "     - Shaded range of extremes (abs tmax: abs tmin)\n",
    "     - Shaded range of means (mean tmax: mean tmin)\n",
    "2. Temperatures for a specified year\n",
    "     - shaded range of tmax: tmin for that year\n",
    "\n",
    "Plot specifications:\n",
    "- Horizontal axis: day of the year\n",
    "- Vertical axis: temperature (deg C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bc6891b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "\n",
    "import pandas as pd, numpy as np\n",
    "from pathlib import Path\n",
    "import fsspec\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c7798a4",
   "metadata": {},
   "source": [
    "### Inventory Available Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "661a2ddb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output: /Users/meganwalker/MDW Docs/Academic/Univ Illinois/ATMS 523/module3/data/ghcn_KGNV.parquet\n"
     ]
    }
   ],
   "source": [
    "# Set up to bring in GHCN data from AWS S3\n",
    " \n",
    "S3_STATIONS_TXT   = \"s3://noaa-ghcn-pds/ghcnd-stations.txt\"\n",
    "S3_INVENTORY_TXT  = \"s3://noaa-ghcn-pds/ghcnd-inventory.txt\"\n",
    "S3_BY_STATION     = \"s3://noaa-ghcn-pds/csv/by_station/{id}.csv\"\n",
    "STOR = {\"anon\": True}\n",
    "\n",
    "OUTDIR = Path('../data'); OUTDIR.mkdir(parents=True, exist_ok=True)\n",
    "OUT_PARQUET = OUTDIR / 'ghcn_KGNV.parquet'\n",
    "OUT_CSV = OUTDIR / 'ghcn_KGNV.csv'\n",
    "print('Output:', OUT_PARQUET.resolve())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b3b6c94b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(            ID  LATITUDE  LONGITUDE  ELEVATION STATE                   NAME  \\\n",
       " 0  ACW00011604   17.1167   -61.7833       10.1        ST JOHNS COOLIDGE FLD   \n",
       " 1  ACW00011647   17.1333   -61.7833       19.2                     ST JOHNS   \n",
       " 2  AE000041196   25.3330    55.5170       34.0          SHARJAH INTER. AIRP   \n",
       " 3  AEM00041194   25.2550    55.3640       10.4                   DUBAI INTL   \n",
       " 4  AEM00041217   24.4330    54.6510       26.8               ABU DHABI INTL   \n",
       " \n",
       "   GSN_FLAG HCN_CRN_FLAG WMO_ID  \n",
       " 0      NaN          NaN    NaN  \n",
       " 1      NaN          NaN    NaN  \n",
       " 2      GSN          NaN  41196  \n",
       " 3      NaN          NaN  41194  \n",
       " 4      NaN          NaN  41217  ,\n",
       "             ID      LAT      LON ELEMENT  FIRSTYEAR  LASTYEAR\n",
       " 0  ACW00011604  17.1167 -61.7833    TMAX       1949      1949\n",
       " 1  ACW00011604  17.1167 -61.7833    TMIN       1949      1949\n",
       " 2  ACW00011604  17.1167 -61.7833    PRCP       1949      1949\n",
       " 3  ACW00011604  17.1167 -61.7833    SNOW       1949      1949\n",
       " 4  ACW00011604  17.1167 -61.7833    SNWD       1949      1949)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load GHCN data from AWS S3 and check out what's available\n",
    "\n",
    "colspecs = [(0,11),(12,20),(21,30),(31,37),(38,40),(41,71),(72,75),(76,79),(80,85)]\n",
    "names = ['ID','LATITUDE','LONGITUDE','ELEVATION','STATE','NAME','GSN_FLAG','HCN_CRN_FLAG','WMO_ID']\n",
    "\n",
    "stations = pd.read_fwf(S3_STATIONS_TXT, colspecs=colspecs, names=names, dtype={'ID':str,'STATE':str,'WMO_ID':str}, storage_options=STOR)\n",
    "stations['NAME'] = stations['NAME'].str.strip(); stations['STATE'] = stations['STATE'].fillna('').str.strip()\n",
    "\n",
    "inventory = pd.read_csv(\n",
    "    S3_INVENTORY_TXT, sep=r'\\s+', names=['ID','LAT','LON','ELEMENT','FIRSTYEAR','LASTYEAR'],\n",
    "    dtype={'ID':str,'ELEMENT':str,'FIRSTYEAR':int,'LASTYEAR':int}, engine='python', storage_options=STOR\n",
    ")\n",
    "\n",
    "stations.head(), inventory.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9f3da59",
   "metadata": {},
   "source": [
    "### Gather data of interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eb016f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get user input for state and city of interest\n",
    "\n",
    "state = input(\"Enter 2-letter state code (e.g., 'FL'): \").strip().upper() # remove accidental whitespace and force the state abbreviation to uppercase\n",
    "city = input(\"Enter city name (e.g., 'Gainesville'): \").strip().upper() # remove accidental whitespace and force the city name to uppercase to match GHCN format\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99ab73aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c2052a12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>NAME</th>\n",
       "      <th>STATE</th>\n",
       "      <th>LATITUDE</th>\n",
       "      <th>LONGITUDE</th>\n",
       "      <th>ELEVATION</th>\n",
       "      <th>first</th>\n",
       "      <th>last</th>\n",
       "      <th>years</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1826</th>\n",
       "      <td>USC00080478</td>\n",
       "      <td>BARTOW 1SE</td>\n",
       "      <td>FL</td>\n",
       "      <td>27.8864</td>\n",
       "      <td>-81.8325</td>\n",
       "      <td>34.1</td>\n",
       "      <td>1892</td>\n",
       "      <td>2025</td>\n",
       "      <td>134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1891</th>\n",
       "      <td>USC00082229</td>\n",
       "      <td>DELAND 1 SSE</td>\n",
       "      <td>FL</td>\n",
       "      <td>29.0097</td>\n",
       "      <td>-81.2986</td>\n",
       "      <td>7.6</td>\n",
       "      <td>1892</td>\n",
       "      <td>2025</td>\n",
       "      <td>134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1903</th>\n",
       "      <td>USC00082944</td>\n",
       "      <td>FERNANDINA BEACH</td>\n",
       "      <td>FL</td>\n",
       "      <td>30.6669</td>\n",
       "      <td>-81.4525</td>\n",
       "      <td>14.9</td>\n",
       "      <td>1892</td>\n",
       "      <td>2025</td>\n",
       "      <td>134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1958</th>\n",
       "      <td>USC00084731</td>\n",
       "      <td>LAKE CITY 2 E</td>\n",
       "      <td>FL</td>\n",
       "      <td>30.1853</td>\n",
       "      <td>-82.5942</td>\n",
       "      <td>59.4</td>\n",
       "      <td>1892</td>\n",
       "      <td>2025</td>\n",
       "      <td>134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021</th>\n",
       "      <td>USC00086414</td>\n",
       "      <td>OCALA</td>\n",
       "      <td>FL</td>\n",
       "      <td>29.1639</td>\n",
       "      <td>-82.0778</td>\n",
       "      <td>22.9</td>\n",
       "      <td>1892</td>\n",
       "      <td>2025</td>\n",
       "      <td>134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2060</th>\n",
       "      <td>USC00087205</td>\n",
       "      <td>PLANT CITY</td>\n",
       "      <td>FL</td>\n",
       "      <td>28.0208</td>\n",
       "      <td>-82.1392</td>\n",
       "      <td>33.2</td>\n",
       "      <td>1892</td>\n",
       "      <td>2025</td>\n",
       "      <td>134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2116</th>\n",
       "      <td>USC00088824</td>\n",
       "      <td>TARPON SPGS SEWAGE PLT</td>\n",
       "      <td>FL</td>\n",
       "      <td>28.1522</td>\n",
       "      <td>-82.7539</td>\n",
       "      <td>1.8</td>\n",
       "      <td>1892</td>\n",
       "      <td>2025</td>\n",
       "      <td>134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2179</th>\n",
       "      <td>USW00012835</td>\n",
       "      <td>FT MYERS PAGE FLD AP</td>\n",
       "      <td>FL</td>\n",
       "      <td>26.5850</td>\n",
       "      <td>-81.8614</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1892</td>\n",
       "      <td>2025</td>\n",
       "      <td>134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2184</th>\n",
       "      <td>USW00012841</td>\n",
       "      <td>ORLANDO EXECUTIVE AP</td>\n",
       "      <td>FL</td>\n",
       "      <td>28.5467</td>\n",
       "      <td>-81.3356</td>\n",
       "      <td>31.7</td>\n",
       "      <td>1892</td>\n",
       "      <td>2025</td>\n",
       "      <td>134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1822</th>\n",
       "      <td>USC00080369</td>\n",
       "      <td>AVON PARK 2 W</td>\n",
       "      <td>FL</td>\n",
       "      <td>27.5947</td>\n",
       "      <td>-81.5267</td>\n",
       "      <td>46.9</td>\n",
       "      <td>1892</td>\n",
       "      <td>2022</td>\n",
       "      <td>131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2081</th>\n",
       "      <td>USC00087851</td>\n",
       "      <td>SAINT LEO</td>\n",
       "      <td>FL</td>\n",
       "      <td>28.3381</td>\n",
       "      <td>-82.2603</td>\n",
       "      <td>52.7</td>\n",
       "      <td>1895</td>\n",
       "      <td>2025</td>\n",
       "      <td>131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1900</th>\n",
       "      <td>USC00082915</td>\n",
       "      <td>FEDERAL PT</td>\n",
       "      <td>FL</td>\n",
       "      <td>29.7550</td>\n",
       "      <td>-81.5389</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1892</td>\n",
       "      <td>2020</td>\n",
       "      <td>129</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               ID                    NAME STATE  LATITUDE  LONGITUDE  \\\n",
       "1826  USC00080478              BARTOW 1SE    FL   27.8864   -81.8325   \n",
       "1891  USC00082229            DELAND 1 SSE    FL   29.0097   -81.2986   \n",
       "1903  USC00082944        FERNANDINA BEACH    FL   30.6669   -81.4525   \n",
       "1958  USC00084731           LAKE CITY 2 E    FL   30.1853   -82.5942   \n",
       "2021  USC00086414                   OCALA    FL   29.1639   -82.0778   \n",
       "2060  USC00087205              PLANT CITY    FL   28.0208   -82.1392   \n",
       "2116  USC00088824  TARPON SPGS SEWAGE PLT    FL   28.1522   -82.7539   \n",
       "2179  USW00012835    FT MYERS PAGE FLD AP    FL   26.5850   -81.8614   \n",
       "2184  USW00012841    ORLANDO EXECUTIVE AP    FL   28.5467   -81.3356   \n",
       "1822  USC00080369           AVON PARK 2 W    FL   27.5947   -81.5267   \n",
       "2081  USC00087851               SAINT LEO    FL   28.3381   -82.2603   \n",
       "1900  USC00082915              FEDERAL PT    FL   29.7550   -81.5389   \n",
       "\n",
       "      ELEVATION  first  last  years  \n",
       "1826       34.1   1892  2025    134  \n",
       "1891        7.6   1892  2025    134  \n",
       "1903       14.9   1892  2025    134  \n",
       "1958       59.4   1892  2025    134  \n",
       "2021       22.9   1892  2025    134  \n",
       "2060       33.2   1892  2025    134  \n",
       "2116        1.8   1892  2025    134  \n",
       "2179        4.0   1892  2025    134  \n",
       "2184       31.7   1892  2025    134  \n",
       "1822       46.9   1892  2022    131  \n",
       "2081       52.7   1895  2025    131  \n",
       "1900        1.5   1892  2020    129  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Narrow down to stations in state of interest with at least 30 years of data (so that climatology can be computed)\n",
    "\n",
    "# Calculate period of record for each station\n",
    "coverage = (inventory.groupby('ID', as_index=False)\n",
    "                    .agg(first=('FIRSTYEAR','min'), last=('LASTYEAR','max'))\n",
    "                    .assign(years=lambda d: d['last'] - d['first'] + 1))\n",
    "\n",
    "state_list = (stations.loc[stations['STATE']==state, ['ID','NAME','STATE','LATITUDE','LONGITUDE','ELEVATION']]\n",
    "              .merge(coverage, on='ID', how='inner'))\n",
    "state30 = state_list[state_list['years']>=30].copy()\n",
    "state30.sort_values(['years','ID'], ascending=[False, True]).head(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "855496a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No stations found matching 'WALDO' in FL.\n",
      "The closest station to this location is GAINESVILLE UNIV OF FL (USC00083316) at distance of 0.03 degrees.\n",
      "The closest station to this location is GAINESVILLE UNIV OF FL (USC00083316) at distance of 0.03 degrees.\n"
     ]
    }
   ],
   "source": [
    "# Search for stations that include the city name provided by the user, and offer the user the option to choose which station to use if multiple matches are found\n",
    "city_stations = state30[state30['NAME'].str.contains(city, na=False)].copy()\n",
    "\n",
    "if not city_stations.empty:\n",
    "    print(f\"Found {len(city_stations)} station(s) matching '{city}' in {state}:\")\n",
    "    display(city_stations)\n",
    "    \n",
    "    # Ask user to select a station from the list\n",
    "    stationID = input(\"Which station would you like to use? Copy and paste the station ID (e.g., 'USW00012839'): \")\n",
    "    print(f\"Using station {city_stations.loc[city_stations['ID'] == stationID, 'NAME'].values[0]} ({stationID})\")\n",
    "\n",
    "else: # if no stations found matching city name, offer user the option to search for the closest station by lat/lon instead\n",
    "    print( f\"No stations found matching '{city}' in {state}.\")\n",
    "    search_option = input(\"Would you like to search for the closest station by latitude/longitude instead? (yes/no): \")\n",
    "    if search_option.lower() == 'yes':\n",
    "        # Get user input for latitude and longitude\n",
    "        city_lat = float(input(\"Enter city latitude (e.g., 29.6516): \").strip()) \n",
    "        city_lon = float(input(\"Enter city longitude (e.g., -82.3248): \").strip())\n",
    "\n",
    "        # Find the closest station by calculating the minimum lat/lon distance from a station to the city coordinates\n",
    "        state30['DISTANCE'] = np.sqrt((state30['LATITUDE'] - city_lat)**2 + (state30['LONGITUDE'] - city_lon)**2)\n",
    "        closest_station = state30.loc[state30['DISTANCE'].idxmin()]\n",
    "        stationID = closest_station['ID']\n",
    "        print(f\"The closest station to this location is {closest_station['NAME']} ({stationID}) at a distance of {closest_station['DISTANCE']:.2f} degrees.\")\n",
    "    else:\n",
    "        print(\"Exiting program.\")\n",
    "        exit()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5cf522c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The GHCN data for GAINESVILLE UNIV OF FL (USC00083316) has (23399, 18) elements\n",
      "USC00083316 (23399, 18)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>ELEMENT</th>\n",
       "      <th>ID</th>\n",
       "      <th>DATE</th>\n",
       "      <th>PRCP</th>\n",
       "      <th>SNOW</th>\n",
       "      <th>SNWD</th>\n",
       "      <th>TMAX</th>\n",
       "      <th>TMIN</th>\n",
       "      <th>TOBS</th>\n",
       "      <th>WT01</th>\n",
       "      <th>WT03</th>\n",
       "      <th>WT04</th>\n",
       "      <th>WT05</th>\n",
       "      <th>WT07</th>\n",
       "      <th>WT08</th>\n",
       "      <th>WT09</th>\n",
       "      <th>WT10</th>\n",
       "      <th>WT11</th>\n",
       "      <th>WT14</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>USC00083316</td>\n",
       "      <td>1890-07-13</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33.3</td>\n",
       "      <td>22.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>USC00083316</td>\n",
       "      <td>1890-07-14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36.7</td>\n",
       "      <td>20.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>USC00083316</td>\n",
       "      <td>1890-07-15</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34.4</td>\n",
       "      <td>21.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>USC00083316</td>\n",
       "      <td>1890-07-16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34.4</td>\n",
       "      <td>21.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>USC00083316</td>\n",
       "      <td>1890-07-17</td>\n",
       "      <td>7.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34.4</td>\n",
       "      <td>22.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "ELEMENT           ID       DATE  PRCP  SNOW  SNWD  TMAX  TMIN  TOBS  WT01  \\\n",
       "0        USC00083316 1890-07-13   0.0   NaN   NaN  33.3  22.2   NaN   NaN   \n",
       "1        USC00083316 1890-07-14   0.0   NaN   NaN  36.7  20.0   NaN   NaN   \n",
       "2        USC00083316 1890-07-15   0.0   NaN   NaN  34.4  21.1   NaN   NaN   \n",
       "3        USC00083316 1890-07-16   0.0   NaN   NaN  34.4  21.1   NaN   NaN   \n",
       "4        USC00083316 1890-07-17   7.6   NaN   NaN  34.4  22.2   NaN   NaN   \n",
       "\n",
       "ELEMENT  WT03  WT04  WT05  WT07  WT08  WT09  WT10  WT11  WT14  \n",
       "0         NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "1         NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "2         NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "3         NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "4         NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the data for the station of interest\n",
    "\n",
    "url = S3_BY_STATION.format(id=stationID)\n",
    "\n",
    "def load_station_daily(url: str) -> pd.DataFrame:\n",
    "    df = pd.read_csv(url, storage_options=STOR, dtype={'ID':str,'ELEMENT':str}, parse_dates=['DATE'])\n",
    "    df['DATA_VALUE'] = df['DATA_VALUE'].replace(-9999, np.nan)\n",
    "    wide = (df.pivot_table(index=['ID','DATE'], columns='ELEMENT', values='DATA_VALUE', aggfunc='first').reset_index())\n",
    "    for c in ('TMAX','TMIN','TAVG'):\n",
    "        if c in wide: wide[c] = wide[c]/10.0\n",
    "    if 'PRCP' in wide: wide['PRCP'] = wide['PRCP']/10.0\n",
    "    return wide.sort_values(['ID','DATE']).reset_index(drop=True)\n",
    "\n",
    "w = load_station_daily(url)\n",
    "print(f\"The GHCN data for {closest_station['NAME']} ({stationID}) has {w.shape} elements\")\n",
    "\n",
    "daily = w.copy()\n",
    "daily.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d97c550a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xarray-climate",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
